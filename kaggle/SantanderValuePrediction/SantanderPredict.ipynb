{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from math import expm1, log1p, sqrt\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import KFold, GridSearchCV, train_test_split, cross_val_score\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import model_selection\n",
    "from sklearn import ensemble\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 12, 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_folds = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X.drop('ID', axis=1, inplace=True)\n",
    "test_id = test.pop('ID')\n",
    "X['target'] = X['target'].apply(lambda x: log1p(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = X.pop('target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed `256` Constant Columns\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cols_to_remove = []\n",
    "for col in X.columns:\n",
    "    if X[col].std() == 0: \n",
    "        cols_to_remove.append(col)\n",
    "        \n",
    "# remove constant columns in the training set\n",
    "X.drop(cols_to_remove, axis=1, inplace=True)\n",
    "# remove constant columns in the test set\n",
    "test.drop(cols_to_remove, axis=1, inplace=True)\n",
    "\n",
    "print(\"Removed `{}` Constant Columns\\n\".format(len(cols_to_remove)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed `4` Duplicate Columns\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cols_to_remove = []\n",
    "cols_scaned = []\n",
    "dups = {}\n",
    "\n",
    "columns = X.columns\n",
    "for i in range(len(columns) - 1):\n",
    "    v = X[columns[i]].values\n",
    "    dup_cols = []\n",
    "    for j in range(i + 1, len(columns)):\n",
    "        if np.array_equal(v, X[columns[j]].values):\n",
    "            cols_to_remove.append(columns[j])\n",
    "            if columns[j] not in cols_scaned:\n",
    "                dup_cols.append(columns[j]) \n",
    "                cols_scaned.append(columns[j])\n",
    "                dups[columns[i]] = dup_cols\n",
    "                \n",
    "# remove duplicate columns in the training set\n",
    "X.drop(cols_to_remove, axis=1, inplace=True) \n",
    "# remove duplicate columns in the testing set\n",
    "test.drop(cols_to_remove, axis=1, inplace=True)\n",
    "\n",
    "print(\"Removed `{}` Duplicate Columns\\n\".format(len(dups)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5367277914935245\n"
     ]
    }
   ],
   "source": [
    "NUM_OF_FEATURES = 1000\n",
    "def rmsle(y, pred):\n",
    "    return np.sqrt(np.mean(np.power(y - pred, 2)))\n",
    "\n",
    "x1, x2, y1, y2 = model_selection.train_test_split(X, y, test_size=0.20, random_state=5)\n",
    "model = ensemble.RandomForestRegressor(n_jobs=-1, random_state=7)\n",
    "model.fit(x1, y1)\n",
    "print(rmsle(y2, model.predict(x2)))\n",
    "\n",
    "col = pd.DataFrame({'importance': model.feature_importances_, 'feature': X.columns}).sort_values(\n",
    "    by=['importance'], ascending=[False])[:NUM_OF_FEATURES]['feature'].values\n",
    "X = X[col]\n",
    "test = test[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rmsle_cv(model):\n",
    "    kf = KFold(n_folds, shuffle=True, random_state=42).get_n_splits(X)\n",
    "    rmse= np.sqrt(-cross_val_score(model, X, y, scoring=\"neg_mean_squared_error\", cv = kf))\n",
    "    return(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "np.any(np.isnan(total_df) False\n",
      "np.all(np.isfinite(total_df) True\n",
      "total_df.columns: RangeIndex(start=0, stop=1000, step=1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import random_projection\n",
    "from sklearn import random_projection\n",
    "from sklearn.preprocessing import scale, MinMaxScaler\n",
    "import gc\n",
    "import itertools\n",
    "from copy import deepcopy\n",
    "import time\n",
    "\n",
    "ntrain = len(X)\n",
    "ntest = len(test)\n",
    "tmp = pd.concat([X, test]) # RandomProjection\n",
    "weight = ((X != 0).sum() / len(X)).values # Non-zero count / total count per column\n",
    "\n",
    "tmp_train = X[X != 0]\n",
    "tmp_test = test[test != 0]\n",
    "X[\"weight_count\"] = (tmp_train * weight).sum(axis=1)\n",
    "test[\"weight_count\"] = (tmp_test * weight).sum(axis=1)\n",
    "X[\"count_not0\"] = (X != 0).sum(axis=1)\n",
    "test[\"count_not0\"] = (test != 0).sum(axis=1)\n",
    "X[\"sum\"] = X.sum(axis=1)\n",
    "test[\"sum\"] = test.sum(axis=1)\n",
    "X[\"var\"] = tmp_train.var(axis=1)\n",
    "test[\"var\"] = tmp_test.var(axis=1)\n",
    "X[\"median\"] = tmp_train.median(axis=1)\n",
    "test[\"median\"] = tmp_test.median(axis=1)\n",
    "X[\"mean\"] = tmp_train.mean(axis=1)\n",
    "test[\"mean\"] = tmp_test.mean(axis=1)\n",
    "X[\"std\"] = tmp_train.std(axis=1)\n",
    "test[\"std\"] = tmp_test.std(axis=1)\n",
    "X[\"max\"] = tmp_train.max(axis=1)\n",
    "test[\"max\"] = tmp_test.max(axis=1)\n",
    "X[\"min\"] = tmp_train.min(axis=1)\n",
    "test[\"min\"] = tmp_test.min(axis=1)\n",
    "del(tmp_train)\n",
    "del(tmp_test)\n",
    "\n",
    "# train data is valid , test data has nan and infinite\n",
    "tmp = pd.DataFrame(np.nan_to_num(tmp))\n",
    "# Go through the columns one at a time (can't do it all at once for this dataset)\n",
    "total_df = deepcopy(tmp)      \n",
    "print('np.any(np.isnan(total_df)', np.any(np.isnan(total_df)))\n",
    "print('np.all(np.isfinite(total_df)', np.all(np.isfinite(total_df)))\n",
    "\n",
    "# Mean-variance scale all columns excluding 0-values'\n",
    "print('total_df.columns:',total_df.columns) \n",
    "columnsCount = len(total_df.columns)\n",
    "for col in total_df.columns:\n",
    "    # Detect outliers in this column\n",
    "    data = total_df[col].values\n",
    "    data_mean, data_std = np.mean(data), np.std(data)\n",
    "    cut_off = data_std * 3\n",
    "    lower, upper = data_mean - cut_off, data_mean + cut_off\n",
    "    outliers = [x for x in data if x < lower or x > upper]\n",
    "    \n",
    "    # If there are crazy high values, do a log-transform\n",
    "    if len(outliers) > 0:\n",
    "        non_zero_idx = data != 0\n",
    "        total_df.loc[non_zero_idx, col] = np.log(data[non_zero_idx])\n",
    "    \n",
    "    # Scale non-zero column values\n",
    "    nonzero_rows = total_df[col] != 0\n",
    "    if  np.isfinite(total_df.loc[nonzero_rows, col]).all():\n",
    "        total_df.loc[nonzero_rows, col] = scale(total_df.loc[nonzero_rows, col])\n",
    "        if  np.isfinite(total_df[col]).all():\n",
    "            # Scale all column values\n",
    "            total_df[col] = scale(total_df[col])\n",
    "    gc.collect()\n",
    "\n",
    "NUM_OF_COM = 100 #need tuned\n",
    "transformer = random_projection.SparseRandomProjection(n_components = NUM_OF_COM)\n",
    "RP = transformer.fit_transform(tmp)\n",
    "rp = pd.DataFrame(RP)\n",
    "columns = [\"RandomProjection{}\".format(i) for i in range(NUM_OF_COM)]\n",
    "rp.columns = columns\n",
    "\n",
    "rp_train = rp[:ntrain]\n",
    "rp_test = rp[ntrain:]\n",
    "rp_test.index = test.index\n",
    "\n",
    "#concat RandomProjection and raw data\n",
    "X = pd.concat([X, rp_train],axis=1)\n",
    "test = pd.concat([test, rp_test],axis=1)\n",
    "\n",
    "del(rp_train)\n",
    "del(rp_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4459, 1109)\n",
      "(49343, 1109)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_xgb = xgb.XGBRegressor(colsample_bytree=0.054, gamma=0.4, \n",
    "                             learning_rate=0.01, max_depth=8, \n",
    "                             min_child_weight=5, n_estimators=1000,\n",
    "                             reg_alpha=1e-05, reg_lambda=0.8571,\n",
    "                             subsample=0.6, random_state =7,\n",
    "                             nthread=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xgboost score: 1.3471 (0.0563)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "score = rmsle_cv(model_xgb)\n",
    "print(\"Xgboost score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_lgb = lgb.LGBMRegressor(objective='regression', num_leaves=144,\n",
    "                              learning_rate=0.005, n_estimators=720, max_depth=13,\n",
    "                              metric='rmse', is_training_metric=True,\n",
    "                              max_bin = 55, bagging_fraction = 0.8,\n",
    "                              bagging_freq = 5, feature_fraction = 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score = rmsle_cv(model_lgb)\n",
    "print(\"LGB score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AveragingModels(BaseEstimator, RegressorMixin, TransformerMixin):\n",
    "    def __init__(self, models):\n",
    "        self.models = models\n",
    "        \n",
    "    # we define clones of the original models to fit the data in\n",
    "    def fit(self, X, y, eval_metric='rmse'):\n",
    "        self.models_ = [clone(x) for x in self.models]\n",
    "        \n",
    "        # Train cloned base models\n",
    "        for model in self.models_:\n",
    "            model.fit(X, y, eval_metric=eval_metric)\n",
    "\n",
    "        return self\n",
    "    \n",
    "    #Now we do the predictions for cloned models and average them\n",
    "    def predict(self, X):\n",
    "        predictions = np.column_stack([\n",
    "            model.predict(X) for model in self.models_\n",
    "        ])\n",
    "        return np.mean(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "averaged_models = AveragingModels(models = (model_xgb, model_lgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averaged base models score: 1.3424 (0.0559)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "score = rmsle_cv(averaged_models)\n",
    "print(\"Averaged base models score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.DataFrame()\n",
    "submit['ID'] = test_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "averaged_models.fit(X, y, eval_metric='rmse')\n",
    "predictions = averaged_models.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submit['target'] = [expm1(x) for x in predictions]\n",
    "submit.to_csv('my_XGB_prediction.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
